{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_RQWrc4cMeS"
      },
      "outputs": [],
      "source": [
        "# Loading the training data set\n",
        "\n",
        "import os\n",
        "import json\n",
        "\n",
        "path = \"../../data/wb_recognition_dataset/train\"\n",
        "len(os.listdir(path))\n",
        "\n",
        "char_id_list = sorted(list(map(int, os.listdir(path))))\n",
        "\n",
        "# Retrieving the number of total samples in the dataset, and saving path for each image\n",
        "sample_count_dict = {}\n",
        "for label_id in char_id_list:\n",
        "    sample_path = path + \"/\" + str(label_id)\n",
        "    list_dir_res = os.listdir(sample_path)\n",
        "\n",
        "    # Creating the dictionary of frequency of labels in training set\n",
        "    sample_count_dict[label_id] = len(list_dir_res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Kd226jYca-N"
      },
      "outputs": [],
      "source": [
        "# Creating a dictionary of {\"path\": \"label\"} for training set\n",
        "\n",
        "path_to_label_dict = {}\n",
        "for label_id in char_id_list:\n",
        "    sample_path = path + \"/\" + str(label_id)\n",
        "    list_dir_res = os.listdir(sample_path)\n",
        "\n",
        "    for image_path in list_dir_res:\n",
        "        full_image_path = sample_path + \"/\" + image_path\n",
        "        path_to_label_dict[full_image_path] = label_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8tNHUUZNc2qn"
      },
      "outputs": [],
      "source": [
        "# Sorting the dictionary by frequency of labels in training set\n",
        "\n",
        "sorted_sample_count_dict = sorted(sample_count_dict.items(), key=lambda x:x[1], reverse=True)\n",
        "train_x = [str(label[0]) for label in sorted_sample_count_dict]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4veeaf5cc5e_"
      },
      "outputs": [],
      "source": [
        "# Creating the train manifest\n",
        "\n",
        "train_manifest = {}\n",
        "\n",
        "for label in train_x:\n",
        "    train_manifest[label] = []\n",
        "\n",
        "    for path in path_to_label_dict:\n",
        "        if path_to_label_dict[path] == int(label):\n",
        "            train_manifest[label].append(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g4Im4k6-dFWO"
      },
      "outputs": [],
      "source": [
        "# Loading the validation dataset\n",
        "\n",
        "import csv\n",
        "\n",
        "csv_path = \"../../data/wb_recognition_dataset/val/labels.csv\"\n",
        "with open(csv_path, \"r\") as csv_file:\n",
        "    reader = csv.reader(csv_file)\n",
        "\n",
        "    header = next(reader)\n",
        "    data_dict = {}\n",
        "\n",
        "    for row in reader:\n",
        "        key = row[0]\n",
        "        value = row[1]\n",
        "\n",
        "        data_dict[key] = value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JPr_kK5_dRm6"
      },
      "outputs": [],
      "source": [
        "# Creating a dictionary of {\"path\": \"label\"} for validation set\n",
        "\n",
        "img_path = \"../../data/wb_recognition_dataset/val/images\"\n",
        "img_path_list = os.listdir(img_path)\n",
        "val_path_to_label = {}\n",
        "\n",
        "for img in img_path_list:\n",
        "    val_full_path = img_path + \"/\" + img\n",
        "    val_path_to_label[val_full_path] = data_dict[img[:-4]]\n",
        "\n",
        "val_image_labels = list(val_path_to_label.values())\n",
        "val_image_paths = list(val_path_to_label.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "bWJb2jE5drke"
      },
      "outputs": [],
      "source": [
        "# Creating the dictionary of frequency of labels in validation set\n",
        "\n",
        "val_label_distribution = {}\n",
        "\n",
        "for label in val_image_labels:\n",
        "    if label not in val_label_distribution.keys():\n",
        "        val_label_distribution[label] = 0\n",
        "\n",
        "    val_label_distribution[label] += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "9ZVwy1hDdpLX"
      },
      "outputs": [],
      "source": [
        "# Sorting the dictionary of frequency of labels in validation set\n",
        "\n",
        "val_sorted_sample_count_dict = sorted(val_label_distribution.items(), key=lambda x:x[1], reverse=True)\n",
        "val_x = [str(label[0]) for label in val_sorted_sample_count_dict]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R0i9Vze-d65y"
      },
      "outputs": [],
      "source": [
        "# Creating the validation set's manifest\n",
        "\n",
        "val_manifest = {}\n",
        "\n",
        "for label in val_x:\n",
        "    val_manifest[label] = []\n",
        "\n",
        "    for path in val_path_to_label:\n",
        "        if int(val_path_to_label[path]) == int(label):\n",
        "            val_manifest[label].append(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Xw-WUYMeFI_"
      },
      "outputs": [],
      "source": [
        "# Combines the 2 sets\n",
        "\n",
        "total_manifest = {\n",
        "    \"train\": train_manifest,\n",
        "    \"val\": val_manifest\n",
        "}\n",
        "\n",
        "with open('../../data/manifest.json', 'w+') as fp:\n",
        "    json.dump(total_manifest, fp, indent=4)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
