{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_folder = \"../results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def get_logits(results_folder):\n",
    "    all_logits = {}\n",
    "    for root, dirs, files in os.walk(results_folder):\n",
    "        \n",
    "        if root == results_folder:\n",
    "            continue\n",
    "        print(root)\n",
    "        model = root.split(\"/\")[-1]\n",
    "        logits = np.load(os.path.join(root, \"logits.npz\"))\n",
    "        all_logits[model] = logits['arr_0']\n",
    "        \n",
    "    return all_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../results/resnet34\n",
      "../results/vgg19\n",
      "../results/resnet18\n",
      "../results/resnet50\n",
      "../results/vgg16\n",
      "dict_keys(['resnet34', 'vgg19', 'resnet18', 'resnet50', 'vgg16'])\n"
     ]
    }
   ],
   "source": [
    "all_logits = get_logits(results_folder)\n",
    "print(all_logits.keys())\n",
    "\n",
    "# ### test\n",
    "# all_logits['resnet18_noagument_2'] = all_logits['resnet18_noagument']\n",
    "# print(all_logits.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "manifest = \"../data/manifest_full.json\"\n",
    "images_folder = \"../data/wb_recognition_dataset/val/images\"\n",
    "\n",
    "def get_filenames(images_folder):\n",
    "    return sorted(os.listdir(images_folder))\n",
    "\n",
    "def get_decodevocab(manifest):\n",
    "    with open(manifest, \"r\") as file:\n",
    "        samples = json.load(file)[\"train\"]\n",
    "    \n",
    "    keys = list(samples.keys())\n",
    "    return dict(zip(range(len(keys)), keys))\n",
    "\n",
    "def decode_labels(preds, decode_vocab):\n",
    "    labels = []\n",
    "    # print(decode_vocab)\n",
    "    for pred in preds:\n",
    "        pred = int(pred)\n",
    "        label = decode_vocab[pred]\n",
    "        labels.append(label)\n",
    "    return labels\n",
    "\n",
    "def soft_ensemble(all_logits, weights):\n",
    "    assert sum(weights) == 1\n",
    "    ensemble_logits = np.zeros(shape=list(all_logits.values())[0].shape)\n",
    "    for i, (model, logits) in enumerate(all_logits.items()):\n",
    "        ensemble_logits += logits * weights[i]\n",
    "    \n",
    "    ensemble_preds = np.argmax(ensemble_logits, axis=1)\n",
    "    decode_vocab = get_decodevocab(manifest)\n",
    "    ensemble_labels = decode_labels(ensemble_preds, decode_vocab)\n",
    "    \n",
    "    filenames = get_filenames(images_folder)\n",
    "    results = {}\n",
    "    for filename, ensemble_label in zip(filenames, ensemble_labels):\n",
    "        results[filename.split('.')[0]] = int(ensemble_label)\n",
    "    \n",
    "    return ensemble_logits, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-36.8645196 , -34.357342  , -36.16119647, ..., -51.13641882,\n",
       "        -55.58463097, -41.32209158],\n",
       "       [-39.75089383, -39.77310944, -41.93241024, ..., -55.00753069,\n",
       "        -55.37384462, -48.56921959],\n",
       "       [-40.22456503, -41.92690444, -30.50220561, ..., -47.89273977,\n",
       "        -59.77570152, -52.05369043],\n",
       "       ...,\n",
       "       [-31.12986851, -22.90482712, -31.55321503, ..., -47.50384283,\n",
       "        -43.75393009, -41.64422941],\n",
       "       [-39.24476814, -35.23463821, -41.24069834, ..., -56.94106054,\n",
       "        -68.84997272, -66.80036974],\n",
       "       [-16.90103889, -12.88231838, -25.65301132, ..., -47.12804604,\n",
       "        -41.65291071, -44.45369101]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_logits, results = soft_ensemble(all_logits, weights=[0.2, 0.2, 0.2, 0.2, 0.2])\n",
    "ensemble_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "def save_csv(result_preds, csv_path):\n",
    "    result_preds = {**{\"image_name\":\"label\"}, **result_preds}\n",
    "    with open(csv_path, mode='w', newline='') as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "        \n",
    "        for filename, class_id in result_preds.items():\n",
    "            writer.writerow([filename, class_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_csv(results, \"../results/ensemble.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sinonom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
