# @package _global_

# to execute this experiment run:
# python train.py experiment=ddpm

defaults:
  - override /data: xla
  - override /model: xla_resnet50 # No layer freezing
  - override /callbacks: default
  - override /trainer: default

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

tags: ["xla", "resnet50"]

seed: 12345

trainer:
  min_epochs: 30
  max_epochs: 56
  gradient_clip_val: 0.5

data:
  manifest: ${paths.data_dir}manifest.json
  batch_size: 512
  num_workers: 8

# ckpt_path: /home/minhlv/Projects/ComputerVision/SinoNom_recognition/logs/train/runs/2024-05-22_16-28-25/checkpoints/epoch_038.ckpt
ckpt_path: /home/minhlv/Projects/ComputerVision/SinoNom_recognition/logs/train/runs/2024-05-22_17-09-28/checkpoints/epoch_056.ckpt